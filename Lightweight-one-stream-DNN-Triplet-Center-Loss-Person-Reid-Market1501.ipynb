{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "import efficientnet.tfkeras as efn \n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import preprocess_crop\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from random_eraser import get_random_eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 299,100\n",
    "batch_size=32\n",
    "input_image_shape = (height,width,3)\n",
    "train_dir = 'MARKET1501/market_rename/train_all'\n",
    " #Total epochs to train.\n",
    "epochs = 120\n",
    "learning_rate_base = 3e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The data, split between train and test sets\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(height, width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50000,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "#datagen_val = ImageDataGenerator()\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(height, width),\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=5000,\n",
    "#     class_mode='binary',\n",
    "#     shuffle=True,\n",
    "#     subset='validation'\n",
    "# )\n",
    "x_train1, y_train1 = train_generator.next()\n",
    "# x_val1, y_val1 = validation_generator.next()\n",
    "x_train1 = x_train1.astype('float32')\n",
    "# x_val11 = x_val1.astype('float32')\n",
    "y_train1 = y_train1.astype('float32')\n",
    "# y_val1 = y_val1.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "\n",
    "\n",
    "class BalancedDataGenerator(Sequence):\n",
    "    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n",
    "    def __init__(self, x, y, datagen, batch_size=32):\n",
    "        self.datagen = datagen\n",
    "        self.batch_size = min(batch_size, x.shape[0])\n",
    "        datagen.fit(x)\n",
    "        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y,\n",
    "                                                                  sampler=RandomOverSampler(), \n",
    "                                                                  batch_size=self.batch_size, keep_sparse=True)\n",
    "        self._shape = (self.steps_per_epoch * batch_size, *x.shape[1:])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_batch, y_batch = self.gen.__next__()\n",
    "        x_batch = x_batch.reshape(-1, *self._shape[1:])\n",
    "        X,y = self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()\n",
    "        y_batch_onehot=to_categorical(y, num_classes=751)\n",
    "#         y_batch_onehot = self.smooth_labels(y_batch_onehot, .1)\n",
    "#         return [X,y],[y_batch_onehot,y]\n",
    "    \n",
    "        return [X,y],[y_batch_onehot,y]\n",
    "\n",
    "\n",
    "# In[148]:\n",
    "datagen = ImageDataGenerator(featurewise_std_normalization=True, featurewise_center=True\n",
    "                             ,horizontal_flip=True,brightness_range=[0.2,1.0],rotation_range=10,\n",
    "                                preprocessing_function=get_random_eraser(v_l=0, v_h=255) )\n",
    "\n",
    "balanced_gen = BalancedDataGenerator(x_train1, y_train1, datagen, batch_size=32)\n",
    "# balanced_gen_val = BalancedDataGenerator(x_val1, y_val1, datagen, batch_size=32)\n",
    "steps_per_epoch = balanced_gen.steps_per_epoch\n",
    "# # steps_per_epoch_val = balanced_gen_val.steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train1, num_classes=751)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def smooth_labels(y, smooth_factor):\n",
    "    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n",
    "    # Arguments\n",
    "        y: matrix of one-hot row-vector labels to be smoothed\n",
    "        smooth_factor: label smoothing factor (between 0 and 1)\n",
    "    # Returns\n",
    "        A matrix of smoothed labels.\n",
    "    '''\n",
    "    assert len(y.shape) == 2\n",
    "    if 0 <= smooth_factor <= 1:\n",
    "        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n",
    "        y *= 1 - smooth_factor\n",
    "        y += smooth_factor / y.shape[1]\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Invalid label smoothing factor: ' + str(smooth_factor))\n",
    "    return y\n",
    "\n",
    "y_train_onehot = smooth_labels(y_train_onehot, .1)\n",
    "# y_val_onehot= smooth_labels(y_val_onehot, .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet+Center Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def triplet_center_loss(y_true, y_pred, n_classes= 10, alpha=0.38):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ', y_pred)\n",
    "\n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    print('total_lenght=',  total_lenght)\n",
    "    #     total_lenght =12\n",
    "\n",
    "    # repeat y_true for n_classes and == np.arange(n_classes)\n",
    "    # repeat also y_pred and apply mask\n",
    "    # obtain min for each column min vector for each class\n",
    "\n",
    "    classes = tf.range(0, n_classes,dtype=tf.float32)\n",
    "    y_pred_r = tf.reshape(y_pred, (tf.shape(y_pred)[0], 1))\n",
    "    y_pred_r = tf.keras.backend.repeat(y_pred_r, n_classes)\n",
    "\n",
    "    y_true_r = tf.reshape(y_true, (tf.shape(y_true)[0], 1))\n",
    "    y_true_r = tf.keras.backend.repeat(y_true_r, n_classes)\n",
    "\n",
    "    mask = tf.equal(y_true_r[:, :, 0], classes)\n",
    "\n",
    "    #mask2 = tf.ones((tf.shape(y_true_r)[0], tf.shape(y_true_r)[1]))  # todo inf\n",
    "\n",
    "    # use tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    masked = y_pred_r[:, :, 0] * tf.cast(mask, tf.float32) #+ (mask2 * tf.cast(tf.logical_not(mask), tf.float32))*tf.constant(float(2**10))\n",
    "    masked = tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    minimums = tf.math.reduce_min(masked, axis=1)\n",
    "\n",
    "    loss = K.max(y_pred - minimums +alpha ,0)\n",
    "\n",
    "    # obtain a mask for each pred\n",
    "\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(input_feature):\n",
    "    #kernel_size = 7\n",
    "    kernel_size = 3\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_stream(image_input_shape,embedding_size,n_class,height,width):\n",
    "   \n",
    "    y = Input(shape=(n_class,))\n",
    "    input_image = Input(shape=image_input_shape)\n",
    "    eff_model=efn.EfficientNetB3(input_shape=(height, width, 3),\n",
    "                                   include_top=False,\n",
    "                                   weights='noisy-student')\n",
    "            \n",
    "    model_backbone = Model(eff_model.input,eff_model.get_layer('block7a_project_bn').output)(input_image)\n",
    "    print(\"backbone :\",model_backbone.shape)\n",
    "      \n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(model_backbone)\n",
    "    s = spatial_attention(s)\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = spatial_attention(s)\n",
    "    s = BatchNormalization()(s)\n",
    "    s = GlobalAveragePooling2D()(s)\n",
    "    s = Dropout(0.3)(s)\n",
    "    \n",
    "    print(\"spatial: \",s.shape)\n",
    "\n",
    "    return s,y,input_image  \n",
    "\n",
    "def fc_reid(x,y,n_class):\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x =  BatchNormalization()(x)\n",
    "    softmax = Dense(n_class, activation='softmax', name='reid_output')(x)\n",
    "\n",
    "    center = Embedding(n_class, embedding_size)(y)\n",
    "    l2_loss = Lambda(lambda x: K.sum(K.square(x[0] - x[1][:, 0]), 1, keepdims=True), name='l2_loss')(\n",
    "        [x, center])\n",
    "    return softmax,l2_loss\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fusion(image_input_shape,embedding_size,n_class,height,width):\n",
    "     \n",
    "    loss_weights = [1, 0.0005]\n",
    "    model,y,input_image = one_stream(image_input_shape,embedding_size,n_class,height,width)\n",
    "    softmax_id ,l2_loss = fc_reid(model,y,n_class)\n",
    "    optimizer = tfa.optimizers.LazyAdam(learning_rate_base)\n",
    "    lr_metric = get_lr_metric(optimizer)\n",
    "    model = tf.keras.models.Model(inputs=[input_image,y], outputs=[softmax_id, l2_loss]) \n",
    "    model.compile(loss={'reid_output':tf.keras.losses.CategoricalCrossentropy(), \n",
    "                        'l2_loss':triplet_center_loss},\n",
    "                  optimizer=optimizer,metrics=['accuracy',lr_metric],\n",
    "                  loss_weights={'reid_output':1,\n",
    "                               'l2_loss':0.0005}\n",
    "                 )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_len =1\n",
    "n_class = 751\n",
    "embedding_size =128\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\", \"/gpu:2\"], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "# with mirrored_strategy.scope():\n",
    "model = create_model_fusion(input_image_shape,embedding_size,n_class,height,width)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create & Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr =learning_rate_base):\n",
    "    if epoch <= 20:\n",
    "#         return 0.0003\n",
    "#         return lr * math.exp(0.45)\n",
    "        return lr * 1.59\n",
    "    if epoch > 20 and epoch <=70:  \n",
    "        return 0.0005\n",
    "    if epoch > 70 and epoch <=100:\n",
    "        return 0.00005\n",
    "    if epoch > 100:\n",
    "        return 0.000005\n",
    "my_lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_tuned(epoch, lr =learning_rate_base):\n",
    "    if epoch <= 2:\n",
    "        return 0.0000003\n",
    "my_lr_tuned = tf.keras.callbacks.LearningRateScheduler(scheduler_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = 'model_one_stream'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='reid_output_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "# stop = EarlyStopping(monitor='val_loss', patience =5,\n",
    "#                       verbose=0, mode='auto', baseline=None, \n",
    "#                       restore_best_weights=False)\n",
    "\n",
    "callbacks = [checkpoint,my_lr_callback]\n",
    "# callbacks = [checkpoint, my_lr_tuned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit([x_train, y_train], [y_train_onehot, y_train], validation_data=([x_val, y_val], [y_val_onehot, y_val]),shuffle=True,verbose=1,batch_size=64,\n",
    "#           epochs=epochs,callbacks=callbacks)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    balanced_gen,\n",
    "#     validation_data=(gen_val),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,     \n",
    "#     validation_steps=steps_per_epoch_val,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['accuracy'],\n",
    "                    name='Train'))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#                     y=history.history['loss'],\n",
    "#                     name='Loss'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for Re-identification feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()\n",
    "\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['loss'],\n",
    "                    name='Loss'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for Re-identification feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('last_epoch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"last_epoch.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
