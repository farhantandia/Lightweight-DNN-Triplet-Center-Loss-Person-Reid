{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import efficientnet.tfkeras as efn \n",
    "import tensorflow as tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, Adadelta,SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import math as m\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "def attach_attention_module(net, attention_module):\n",
    "    if attention_module == 'se_block': # SE_block\n",
    "        net = se_block(net)\n",
    "    elif attention_module == 'cbam_block': # CBAM_block\n",
    "        net = cbam_block(net)\n",
    "    else:\n",
    "        raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\n",
    "\n",
    "    return net\n",
    "\n",
    "def cbam_block(cbam_feature, ratio=2):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "#     cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "    cbam_feature = tf.keras.layers.Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 3\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "def one_stream(image_input_shape,embedding_size,n_class,height,width):\n",
    "   \n",
    "    y = Input(shape=(n_class,))\n",
    "    input_image = Input(shape=image_input_shape)\n",
    "    eff_model=efn.EfficientNetB3(input_shape=(height, width, 3),\n",
    "                                   include_top=False,\n",
    "                                   weights='noisy-student')\n",
    "            \n",
    "    model_backbone = Model(eff_model.input,eff_model.get_layer('block7a_project_bn').output)(input_image)\n",
    "    print(\"backbone :\",model_backbone.shape)\n",
    "      \n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(model_backbone)\n",
    "    s = spatial_attention(s)\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = spatial_attention(s)\n",
    "    s = BatchNormalization()(s)\n",
    "    s = GlobalAveragePooling2D()(s)\n",
    "    s = Dropout(0.3)(s)\n",
    "    \n",
    "    print(\"spatial: \",s.shape)\n",
    "\n",
    "    return s,y,input_image  \n",
    "    \n",
    "seq_len=1\n",
    "def fusion_3(image_input_shape,embedding_size,n_class,height,width):\n",
    "   \n",
    "    y = Input(shape=(n_class,))\n",
    "    input_image = Input(batch_shape=(None, seq_len,height, width, 3))\n",
    "    eff_model=efn.EfficientNetB3(input_shape=(height, width, 3),\n",
    "                                 include_top=False,\n",
    "                                 weights='noisy-student')\n",
    "    model_backbone = Model(eff_model.input,eff_model.get_layer('block7a_project_bn').output)\n",
    "    timeDistributed_layer = tf.keras.layers.TimeDistributed(model_backbone)(input_image)\n",
    "    print(\"TimeDistributed\", timeDistributed_layer.shape)\n",
    "    \n",
    "    '''Temporal'''\n",
    "    t = tf.keras.layers.TimeDistributed(GlobalAveragePooling2D())(timeDistributed_layer)\n",
    "    t = LSTM(256, return_sequences=True, input_shape=(t.shape[1],t.shape[2]), name=\"lstm_layer_in\")(t)\n",
    "    t = SeqSelfAttention(attention_activation='sigmoid')(t)\n",
    "    avg_pool = GlobalAveragePooling1D()(t)\n",
    "    max_pool = GlobalMaxPooling1D()(t)\n",
    "    t = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    t = Dropout(0.3)(t)\n",
    "    print(\"Temporal: \", t.shape)\n",
    "    \n",
    "    '''Spatial'''\n",
    "    s = tf.math.reduce_mean(timeDistributed_layer, axis=1)  \n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = cbam_block(s)\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = cbam_block(s)\n",
    "    s = BatchNormalization()(s)\n",
    "    a = GlobalAveragePooling2D()(s)\n",
    "    c = Dropout(0.3)(a)\n",
    "    print(\"Spatial: \", s.shape)\n",
    "        \n",
    "    '''Fusion'''\n",
    "    f = tf.keras.layers.Concatenate()([c, t])\n",
    "    f = Dropout(0.3)(f)\n",
    "    print(\"Fusion: \", f.shape)\n",
    "    return f,y,input_image  \n",
    "\n",
    "def fc_reid(x,y,n_class):\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    x =  BatchNormalization()(x)\n",
    "    #     x = tf.math.l2_normalize(x, axis=1)\n",
    "    softmax = Dense(n_class, activation='softmax', name='reid_output')(x)\n",
    "\n",
    "    center = Embedding(n_class, embedding_size)(y)\n",
    "    l2_loss = Lambda(lambda x: K.sum(K.square(x[0] - x[1][:, 0]), 1, keepdims=True), name='l2_loss')(\n",
    "        [x, center])\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def create_model(image_input_shape,embedding_size,n_class,height,width):\n",
    "    \n",
    "    model,y,input_image = fusion_3(image_input_shape,embedding_size,n_class,height,width)\n",
    "    softmax_id = fc_reid(model,y,n_class)\n",
    "     \n",
    "    return tf.keras.models.Model(inputs=[input_image,y], outputs=[softmax_id])\n",
    "\n",
    "def triplet_center_loss(y_true, y_pred, n_classes= 10, alpha=0.38):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ', y_pred)\n",
    "\n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    #     print('total_lenght=',  total_lenght)\n",
    "    #     total_lenght =12\n",
    "\n",
    "    # repeat y_true for n_classes and == np.arange(n_classes)\n",
    "    # repeat also y_pred and apply mask\n",
    "    # obtain min for each column min vector for each class\n",
    "\n",
    "    classes = tf.range(0, n_classes,dtype=tf.float32)\n",
    "    y_pred_r = tf.reshape(y_pred, (tf.shape(y_pred)[0], 1))\n",
    "    y_pred_r = tf.keras.backend.repeat(y_pred_r, n_classes)\n",
    "\n",
    "    y_true_r = tf.reshape(y_true, (tf.shape(y_true)[0], 1))\n",
    "    y_true_r = tf.keras.backend.repeat(y_true_r, n_classes)\n",
    "\n",
    "    mask = tf.equal(y_true_r[:, :, 0], classes)\n",
    "\n",
    "    #mask2 = tf.ones((tf.shape(y_true_r)[0], tf.shape(y_true_r)[1]))  # todo inf\n",
    "\n",
    "    # use tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    masked = y_pred_r[:, :, 0] * tf.cast(mask, tf.float32) #+ (mask2 * tf.cast(tf.logical_not(mask), tf.float32))*tf.constant(float(2**10))\n",
    "    masked = tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    minimums = tf.math.reduce_min(masked, axis=1)\n",
    "\n",
    "    loss = K.max(y_pred - minimums +alpha ,0)\n",
    "\n",
    "    # obtain a mask for each pred\n",
    "    return loss\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    " \n",
    "optimizer = tfa.optimizers.LazyAdam()\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "height, width =299,100\n",
    "loss_weights = [1, 0.0005]\n",
    "n_class = 751\n",
    "embedding_size =128\n",
    "batch_size=64\n",
    "nb_frame = 1\n",
    "\n",
    "input_image_shape = (nb_frame,height,width,3) #if two stream\n",
    "# input_image_shape = (height,width,3) #if one stream\n",
    "\n",
    "model = create_model(input_image_shape,embedding_size,n_class,height,width) \n",
    "# model.load_weights(\"combine.hdf5\")\n",
    "\n",
    "'''LOAD WEIGHTS'''\n",
    "# model.load_weights(\"model_combine_2/variables/variables\")\n",
    "# model.load_weights('model_MTDNN/variables/variables')\n",
    "model.compile(loss=[\"categorical_crossentropy\", triplet_center_loss],optimizer=tfa.optimizers.LazyAdam(0.0001),metrics=['accuracy'],loss_weights=loss_weights)\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cross_entropy_loss(real_score, predict_score):\n",
    "    predict_prob = 1 / (1 + K.exp(-predict_score))\n",
    "    real_prob = 1 / (1 + K.exp(-real_score))\n",
    "    cross_entropy = -real_prob * K.log(predict_prob) - (1 - real_prob) * K.log(1 - predict_prob)\n",
    "    return cross_entropy\n",
    "def write(path, content):\n",
    "    with open(path, \"a+\") as dst_file:\n",
    "        dst_file.write(content)\n",
    "\n",
    "def safe_remove(path):\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def extract_info(dir_path):\n",
    "    infos = []\n",
    "    for image_name in sorted(os.listdir(dir_path)):\n",
    "        if 'f' in image_name or 's' in image_name:\n",
    "            arr = image_name.split('_')\n",
    "            try : \n",
    "                person = int(arr[0])\n",
    "        #         person = (str(person))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            try :\n",
    "                camera = int(arr[1][1])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        elif 's' not in image_name:\n",
    "            # grid\n",
    "            arr = image_name.split('_')\n",
    "            person = int(arr[0])\n",
    "            camera = int(arr[1])\n",
    "        else:\n",
    "            continue\n",
    "        infos.append((person, camera))\n",
    "\n",
    "    return infos\n",
    "\n",
    "class ReshapeLayer(Layer):\n",
    "    def call(self,inputs):\n",
    "        nshape = (1) + inputs.shape[0:]\n",
    "        return tf.reshape(inputs,nshape)\n",
    "\n",
    "def extract_feature(dir_path, net, height, width,nb_frame):\n",
    "    datagen = ImageDataGenerator(featurewise_std_normalization=True,featurewise_center=True)\n",
    "    features = []\n",
    "    infos = []\n",
    "    print('Extracting all test data, please wait...')\n",
    "    for image_name in sorted(os.listdir(dir_path)):\n",
    "        #if '.txt' in image_name:\n",
    "            #continue\n",
    "        if 'f' in image_name or 's' in image_name:\n",
    "            arr = image_name.split('_')\n",
    "            try : \n",
    "                person = int(arr[0])\n",
    "                #print(person)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            try :\n",
    "                camera = int(arr[1][1])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        elif 's' not in image_name:\n",
    "            # grid\n",
    "            arr = image_name.split('_')\n",
    "            person = int(arr[0])\n",
    "            camera = int(arr[1])\n",
    "        else:\n",
    "            continue\n",
    "        image_path = os.path.join(dir_path, image_name)\n",
    "        img = image.load_img(image_path, target_size=( height, width))\n",
    "        x = image.img_to_array(img)\n",
    "        \n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#         x /= 255.0 #normalize image\n",
    "#         x = ReshapeLayer()(x) #for multi image\n",
    "        \n",
    "        feature = net.predict(x)\n",
    "        feature /= np.linalg.norm(feature, axis=1, keepdims=True)\n",
    "        features.append(np.squeeze(feature))\n",
    "        infos.append((person, camera))\n",
    "\n",
    "    return features, infos\n",
    "\n",
    "\n",
    "def similarity_matrix(query_f, test_f):\n",
    "    # Tensorflow graph\n",
    "    # use GPU to calculate the similarity matrix\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    query_t = tf.compat.v1.placeholder(tf.float32, (None, None))\n",
    "    test_t = tf.compat.v1.placeholder(tf.float32, (None, None))\n",
    "    query_t_norm = tf.nn.l2_normalize(query_t, axis=1)\n",
    "    test_t_norm = tf.nn.l2_normalize(test_t, axis=1)\n",
    "    tensor = tf.matmul(query_t_norm, test_t_norm, transpose_a=False, transpose_b=True)\n",
    "\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "    result = sess.run(tensor, {query_t: query_f, test_t: test_f})\n",
    "    print(result.shape)\n",
    "    # descend\n",
    "    return result\n",
    "\n",
    "\n",
    "def sort_similarity(query_f, test_f):\n",
    "    result = similarity_matrix(query_f, test_f)\n",
    "    result_argsort = np.argsort(-result, axis=1)\n",
    "    return result, result_argsort\n",
    "\n",
    "\n",
    "def map_rank_quick_eval(query_info, test_info, result_argsort):\n",
    "    # much more faster than hehefan's evaluation\n",
    "    match = []\n",
    "    junk = []\n",
    "    QUERY_NUM = len(query_info)\n",
    "\n",
    "    for q_index, (qp, qc) in enumerate(query_info):\n",
    "        tmp_match = []\n",
    "        tmp_junk = []\n",
    "        for t_index in range(len(test_info)):\n",
    "            p_t_idx = result_argsort[q_index][t_index]\n",
    "            p_info = test_info[int(p_t_idx)]\n",
    "\n",
    "            tp = p_info[0]\n",
    "            tc = p_info[1]\n",
    "            if tp == qp and qc != tc:\n",
    "                tmp_match.append(t_index)\n",
    "            elif tp == qp or tp == -1:\n",
    "                tmp_junk.append(t_index)\n",
    "        match.append(tmp_match)\n",
    "        junk.append(tmp_junk)\n",
    "\n",
    "    rank_1 = 0.0\n",
    "    rank_5 = 0.0\n",
    "    rank_10 = 0.0\n",
    "    mAP = 0.0\n",
    "    for idx in range(len(query_info)):\n",
    "        if idx % 100 == 0:\n",
    "            print('evaluate img %d' % idx)\n",
    "        recall = 0.0\n",
    "        precision = 1.0\n",
    "        ap = 0.0\n",
    "        YES = match[idx]\n",
    "        IGNORE = junk[idx]\n",
    "        ig_cnt = 0\n",
    "        for ig in IGNORE:\n",
    "            if len(YES) > 0 and ig < YES[0]:\n",
    "                ig_cnt += 1\n",
    "            else:\n",
    "                break\n",
    "        if len(YES) > 0 and ig_cnt >= YES[0]:\n",
    "            rank_1 += 1\n",
    "        if len(YES) > 0 and ig_cnt >= YES[0] - 4:\n",
    "            rank_5 += 1\n",
    "        if len(YES) > 0 and ig_cnt >= YES[0] - 9:\n",
    "            rank_10 += 1\n",
    "        for i, k in enumerate(YES):\n",
    "            ig_cnt = 0\n",
    "            for ig in IGNORE:\n",
    "                if ig < k:\n",
    "                    ig_cnt += 1\n",
    "                else:\n",
    "                    break\n",
    "            cnt = k + 1 - ig_cnt\n",
    "            hit = i + 1\n",
    "            tmp_recall = hit / len(YES)\n",
    "            tmp_precision = hit / cnt\n",
    "            ap = ap + (tmp_recall - recall) * ((precision + tmp_precision) / 2)\n",
    "            recall = tmp_recall\n",
    "            precision = tmp_precision\n",
    "\n",
    "        mAP += ap\n",
    "    rank1_acc = rank_1 / QUERY_NUM\n",
    "    rank5_acc = rank_5 / QUERY_NUM\n",
    "    rank10_acc = rank_10 / QUERY_NUM\n",
    "    mAP = mAP / QUERY_NUM\n",
    "    print('Rank 1:\\t%f' % rank1_acc)\n",
    "    print('Rank 5:\\t%f' % (rank_5 / QUERY_NUM))\n",
    "    print('Rank 10:\\t%f' % (rank_10 / QUERY_NUM))\n",
    "    print('mAP:\\t%f' % mAP)\n",
    "    # np.savetxt('rank_1.log', np.array(rank1_list), fmt='%d')\n",
    "    return rank1_acc, rank5_acc, rank10_acc, mAP\n",
    "\n",
    "\n",
    "def train_predict(net, train_path, pid_path, score_path):\n",
    "    # net = Model(inputs=[net.input], outputs=[net.get_layer('avg_pool').output])\n",
    "    train_f, test_info = extract_feature(train_path, net,height, width,nb_frame)\n",
    "    np.savetxt(score_path.replace('renew_ac.log', 'feature.txt'), train_f, fmt='%.4f')\n",
    "    result, result_argsort = sort_similarity(train_f, train_f)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i][result_argsort[i]]\n",
    "    result = np.array(result)\n",
    "    # ignore top1 because it's the origin image\n",
    "\n",
    "    np.savetxt(score_path.replace('.log', '.txt'), result, fmt='%.4f')\n",
    "    np.savetxt(pid_path.replace('.log', '.txt'), result_argsort, fmt='%d')\n",
    "\n",
    "    np.savetxt(score_path, result[:, 1:], fmt='%.4f')\n",
    "    np.savetxt(pid_path, result_argsort[:, 1:], fmt='%d')\n",
    "    return result\n",
    "\n",
    "\n",
    "def test_predict(net, probe_path, gallery_path, pid_path, score_path, height, width, nb_frame):\n",
    "    # net = Model(inputs=[net.get_layer('resnet50').get_input_at(0)], outputs=[net.get_layer('resnet50').get_output_at(0)])\n",
    "    #net = Model(inputs=[net.input], outputs=[net.get_layer('avg_pool').output])\n",
    "    test_f, test_info = extract_feature(gallery_path, net, height, width,nb_frame)\n",
    "    print(\"Features Gallery Extracted\")\n",
    "    query_f, query_info = extract_feature(probe_path, net, height, width,nb_frame)\n",
    "    print(\"Features Query Extracted\")\n",
    "    print(\"Calculating similarity..\")\n",
    "    result, result_argsort = sort_similarity(query_f, test_f)\n",
    "    print(\"Similarity calculated\")\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i][result_argsort[i]]\n",
    "    result = np.array(result)\n",
    "    safe_remove(pid_path)\n",
    "    safe_remove(score_path)\n",
    "    np.savetxt(pid_path, result_argsort, fmt='%d')\n",
    "    np.savetxt(score_path, result, fmt='%.4f')\n",
    "\n",
    "\n",
    "def train_sepbn_predict(net_path, train_path, pid_path, score_path):\n",
    "    # model = load_model(net_path, custom_objects={'cross_entropy_loss': cross_entropy_loss})\n",
    "    # net = Model(inputs=[model.get_layer('resnet50').get_input_at(0)[1]],\n",
    "    #             outputs=[model.get_layer('resnet50').get_output_at(0)[1]])\n",
    "    train_f, test_info = extract_feature(train_path, net)\n",
    "    result, result_argsort = sort_similarity(train_f, train_f)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i][result_argsort[i]]\n",
    "    result = np.array(result)\n",
    "    # ignore top1 because it's the origin image\n",
    "    np.savetxt(score_path, result[:, 1:], fmt='%.4f')\n",
    "    np.savetxt(pid_path, result_argsort[:, 1:], fmt='%d')\n",
    "    return result\n",
    "\n",
    "\n",
    "def test_sepbn_predict(net_path, probe_path, gallery_path, pid_path, score_path):\n",
    "    model = load_model(net_path, custom_objects={'cross_entropy_loss': cross_entropy_loss})\n",
    "    model = Model(inputs=[model.get_layer('resnet50').get_input_at(0)[1]],\n",
    "                  outputs=[model.get_layer('resnet50').get_output_at(0)[1]])\n",
    "    test_f, test_info = extract_feature(gallery_path, model)\n",
    "    query_f, query_info = extract_feature(probe_path, model)\n",
    "    result, result_argsort = sort_similarity(query_f, test_f)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i][result_argsort[i]]\n",
    "    result = np.array(result)\n",
    "    safe_remove(pid_path)\n",
    "    safe_remove(score_path)\n",
    "    np.savetxt(pid_path, result_argsort, fmt='%d')\n",
    "    np.savetxt(score_path, result, fmt='%.4f')\n",
    "\n",
    "\n",
    "def market_result_eval(predict_path, log_path='market_result_eval.log', TEST='Market-1501/test',\n",
    "                       QUERY='Market-1501/probe'):\n",
    "    res = np.genfromtxt(predict_path, delimiter=' ')\n",
    "    print('predict info get, extract gallery info start')\n",
    "    test_info = extract_info(TEST)\n",
    "    print('extract probe info start')\n",
    "    query_info = extract_info(QUERY)\n",
    "    print('start evaluate map and rank acc')\n",
    "    rank1_acc, rank5_acc, rank10_acc, mAP = map_rank_quick_eval(query_info, test_info, res)\n",
    "    write(log_path, predict_path + '\\n')\n",
    "    write(log_path, 'rank 1: %f rank 5: %f rank 10: %f mAP: %f\\n' % (rank1_acc, rank5_acc, rank10_acc, mAP))\n",
    "\n",
    "\n",
    "def grid_result_eval(predict_path, log_path='grid_eval.log'):\n",
    "    pids4probes = np.genfromtxt(predict_path, delimiter=' ')\n",
    "    probe_shoot = [0, 0, 0, 0, 0]\n",
    "    for i, pids in enumerate(pids4probes):\n",
    "        for j, pid in enumerate(pids):\n",
    "            if pid - i == 775:\n",
    "                if j == 0:\n",
    "                    for k in range(5):\n",
    "                        probe_shoot[k] += 1\n",
    "                elif j < 5:\n",
    "                    for k in range(1, 5):\n",
    "                        probe_shoot[k] += 1\n",
    "                elif j < 10:\n",
    "                    for k in range(2, 5):\n",
    "                        probe_shoot[k] += 1\n",
    "                elif j < 20:\n",
    "                    for k in range(3, 5):\n",
    "                        probe_shoot[k] += 1\n",
    "                elif j < 50:\n",
    "                    for k in range(4, 5):\n",
    "                        probe_shoot[k] += 1\n",
    "                break\n",
    "    probe_acc = [shoot / len(pids4probes) for shoot in probe_shoot]\n",
    "    write(log_path, predict_path + '\\n')\n",
    "    write(log_path, '%.2f\\t%.2f\\t%.2f\\n' % (probe_acc[0], probe_acc[1], probe_acc[2]))\n",
    "    return probe_acc[3]\n",
    "    # print(predict_path)\n",
    "    # print(probe_acc)\n",
    "\n",
    "net = model\n",
    "probe_path ='MARKET1501/probe/'\n",
    "gallery_path = 'MARKET1501/test/'\n",
    "train_path = '../MARKET1501/market_rename/train_all'\n",
    "pid_path = 'ret_train_pid.txt'\n",
    "score_path = 'ret_train_score.txt'\n",
    "test_predict(net, probe_path, gallery_path,  pid_path, score_path, height, width,nb_frame)\n",
    "print(\"Prediction done, start evaluate..\")\n",
    "market_result_eval(pid_path, 'market_eval.txt', gallery_path, probe_path)\n",
    "print(\"Evaluate done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
