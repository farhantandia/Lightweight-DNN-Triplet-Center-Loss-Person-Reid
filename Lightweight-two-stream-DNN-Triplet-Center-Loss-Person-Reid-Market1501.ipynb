{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "import efficientnet.tfkeras as efn \n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras import regularizers\n",
    "from tweaked_ImageGenerator_v2 import ImageDataGenerator as SeqImageGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import preprocess_crop\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from random_eraser import get_random_eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 299,100\n",
    "batch_size=32\n",
    "nb_frame = 1\n",
    "input_image_shape = (nb_frame,height,width,3)\n",
    "train_dir = 'MARKET1501/market_rename/train_all'\n",
    "epochs = 120\n",
    "learning_rate_base = 3e-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The data, split between train and test sets\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(height, width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50000,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "#datagen_val = ImageDataGenerator()\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(height, width),\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=5000,\n",
    "#     class_mode='binary',\n",
    "#     shuffle=True,\n",
    "#     subset='validation'\n",
    "# )\n",
    "x_train1, y_train1 = train_generator.next()\n",
    "# x_val1, y_val1 = validation_generator.next()\n",
    "x_train1 = x_train1.astype('float32')\n",
    "# x_val11 = x_val1.astype('float32')\n",
    "y_train1 = y_train1.astype('float32')\n",
    "# y_val1 = y_val1.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeLayer(Layer):\n",
    "    def call(self,inputs):\n",
    "        nshape = (12936,1) + inputs.shape[1:]\n",
    "        return tf.reshape(inputs,nshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen = SeqImageGenerator(horizontal_flip=True,rotation_range=10,shear_range=0.2,\n",
    "                            preprocessing_function=get_random_eraser(v_l=0, v_h=255))\n",
    "# datagen.fit(x_train1)\n",
    "seq_gen=datagen.flow_from_directory(train_dir, target_size=(height, width), batch_size=batch_size, frames_per_step=nb_frame)\n",
    "\n",
    "steps_per_epoch=12936//batch_size\n",
    "print(steps_per_epoch)\n",
    "# datagenval = ImageDataGenerator()\n",
    "# val_data=datagenval.flow_from_directory(valid_folder, target_size=(height, width), batch_size=batch_size, frames_per_step=nb_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Center Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def triplet_center_loss(y_true, y_pred, n_classes= 10, alpha=0.38):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ', y_pred)\n",
    "\n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    print('total_lenght=',  total_lenght)\n",
    "    #     total_lenght =12\n",
    "\n",
    "    # repeat y_true for n_classes and == np.arange(n_classes)\n",
    "    # repeat also y_pred and apply mask\n",
    "    # obtain min for each column min vector for each class\n",
    "\n",
    "    classes = tf.range(0, n_classes,dtype=tf.float32)\n",
    "    y_pred_r = tf.reshape(y_pred, (tf.shape(y_pred)[0], 1))\n",
    "    y_pred_r = tf.keras.backend.repeat(y_pred_r, n_classes)\n",
    "\n",
    "    y_true_r = tf.reshape(y_true, (tf.shape(y_true)[0], 1))\n",
    "    y_true_r = tf.keras.backend.repeat(y_true_r, n_classes)\n",
    "\n",
    "    mask = tf.equal(y_true_r[:, :, 0], classes)\n",
    "\n",
    "    #mask2 = tf.ones((tf.shape(y_true_r)[0], tf.shape(y_true_r)[1]))  # todo inf\n",
    "\n",
    "    # use tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    masked = y_pred_r[:, :, 0] * tf.cast(mask, tf.float32) #+ (mask2 * tf.cast(tf.logical_not(mask), tf.float32))*tf.constant(float(2**10))\n",
    "    masked = tf.where(tf.equal(masked, 0.0), np.inf*tf.ones_like(masked), masked)\n",
    "\n",
    "    minimums = tf.math.reduce_min(masked, axis=1)\n",
    "\n",
    "    loss = K.max(y_pred - minimums +alpha ,0)\n",
    "\n",
    "    # obtain a mask for each pred\n",
    "\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(input_feature):\n",
    "    #kernel_size = 7\n",
    "    kernel_size = 3\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\t\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "def fusion_3(image_input_shape,embedding_size,n_class,height,width):\n",
    "   \n",
    "    y = Input(shape=(n_class,))\n",
    "    input_image = Input(batch_shape=(None, seq_len,height, width, 3))\n",
    "    eff_model=efn.EfficientNetB3(input_shape=(height, width, 3),\n",
    "                                 include_top=False,\n",
    "                                 weights='noisy-student')\n",
    "    model_backbone = Model(eff_model.input,eff_model.get_layer('block7a_project_bn').output)\n",
    "    timeDistributed_layer = tf.keras.layers.TimeDistributed(model_backbone)(input_image)\n",
    "    print(\"TimeDistributed\", timeDistributed_layer.shape)\n",
    "    \n",
    "    '''Temporal'''\n",
    "    t = tf.keras.layers.TimeDistributed(GlobalAveragePooling2D())(timeDistributed_layer)\n",
    "    t = LSTM(256, return_sequences=True, input_shape=(t.shape[1],t.shape[2]), name=\"lstm_layer_in\")(t)\n",
    "    t = SeqSelfAttention(attention_activation='sigmoid')(t)\n",
    "    avg_pool = GlobalAveragePooling1D()(t)\n",
    "    max_pool = GlobalMaxPooling1D()(t)\n",
    "    t = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    t = Dropout(0.3)(t)\n",
    "    print(\"Temporal: \", t.shape)\n",
    "    \n",
    "    '''Spatial'''\n",
    "    s = tf.math.reduce_mean(timeDistributed_layer, axis=1)   \n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = spatial_attention(s)\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\n",
    "    s = spatial_attention(s)\n",
    "    s = BatchNormalization()(s)\n",
    "    a = GlobalAveragePooling2D()(s)\n",
    "    c = Dropout(0.3)(a)\n",
    "    print(\"Spatial: \", s.shape)\n",
    "    \n",
    "        \n",
    "    '''Fusion'''\n",
    "    f = tf.keras.layers.Concatenate()([c, t])\n",
    "    f = Dropout(0.3)(f)\n",
    "    print(\"Fusion: \", f.shape)\n",
    "    return f,y,input_image  \n",
    "\n",
    "def fc_reid(x,y,n_class):\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x =  BatchNormalization()(x)\n",
    "    softmax = Dense(n_class, activation='softmax', name='reid_output')(x)\n",
    "\n",
    "    center = Embedding(n_class, embedding_size)(y)\n",
    "    l2_loss = Lambda(lambda x: K.sum(K.square(x[0] - x[1][:, 0]), 1, keepdims=True), name='l2_loss')(\n",
    "        [x, center])\n",
    "    return softmax,l2_loss\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create & Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fusion(image_input_shape,embedding_size,n_class,height,width):\n",
    "     \n",
    "    loss_weights = [1, 0.0005]\n",
    "    model,y,input_image = fusion_3(image_input_shape,embedding_size,n_class,height,width)\n",
    "    softmax_id ,l2_loss = fc_reid(model,y,n_class)\n",
    "    optimizer = tfa.optimizers.LazyAdam(learning_rate_base)\n",
    "    lr_metric = get_lr_metric(optimizer)\n",
    "    model = tf.keras.models.Model(inputs=[input_image,y], outputs=[softmax_id, l2_loss]) \n",
    "    model.compile(loss={'reid_output':tf.keras.losses.CategoricalCrossentropy(), \n",
    "                        'l2_loss':triplet_center_loss},\n",
    "                  optimizer=optimizer,metrics=['accuracy',lr_metric],\n",
    "                  loss_weights={'reid_output':1,\n",
    "                               'l2_loss':0.0005}\n",
    "                 )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_len =1\n",
    "n_class = 751\n",
    "embedding_size =128\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\", \"/gpu:2\"], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "# with mirrored_strategy.scope():\n",
    "model = create_model_fusion(input_image_shape,embedding_size,n_class,height,width)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = 'model_two_stream'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='reid_output_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "# stop = EarlyStopping(monitor='val_loss', patience =5,\n",
    "#                       verbose=0, mode='auto', baseline=None, \n",
    "#                       restore_best_weights=False)\n",
    "def scheduler(epoch, lr =learning_rate_base):\n",
    "    if epoch <= 20:\n",
    "#         return 0.0003\n",
    "#         return lr * math.exp(0.45)\n",
    "        return lr * 1.59\n",
    "    if epoch > 20 and epoch <=70:  \n",
    "        return 0.0005\n",
    "    if epoch > 70 and epoch <=100:\n",
    "        return 0.00005\n",
    "    if epoch > 100:\n",
    "        return 0.000005\n",
    "    \n",
    "def scheduler_tuned(epoch, lr =learning_rate_base):\n",
    "    if epoch <= 2:\n",
    "        return 0.0000003\n",
    "my_lr_tuned = tf.keras.callbacks.LearningRateScheduler(scheduler_tuned)\n",
    "\n",
    "my_lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "callbacks = [checkpoint,my_lr_callback]\n",
    "# callbacks = [checkpoint, my_lr_tuned]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    seq_gen,\n",
    "#     validation_data=(gen_val),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,     \n",
    "#     validation_steps=steps_per_epoch_val,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['accuracy'],\n",
    "                    name='Train'))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#                     y=history.history['loss'],\n",
    "#                     name='Loss'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for Re-identification feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()\n",
    "\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['loss'],\n",
    "                    name='Loss'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for Re-identification feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load last weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('combine.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_combine_fix/variables/variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
